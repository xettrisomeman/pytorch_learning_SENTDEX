{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms , datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST('' , train=True , download=True , \n",
    "        transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  datasets.MNIST('' , train=False , download=True , \n",
    "        transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train , batch_size=10,shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test , batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28 , 64)\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))        \n",
    "        x = F.relu(self.fc3(x))        \n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(28,28)\n",
    "X = X.view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1471, -2.4213, -2.2404, -2.3367, -2.3687, -2.2023, -2.3543, -2.2301,\n",
       "         -2.4004, -2.3646]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0651, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1085, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters() , lr = 0.001)\n",
    "\n",
    "\n",
    "epochs =3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output,y)\n",
    "        #backpropagate the loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.975\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X ,y =data\n",
    "        output = net(X.view(-1,784))\n",
    "        for idx , i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct+=1\n",
    "            total +=1\n",
    "            \n",
    "print('Accuracy: ' , round(correct/total,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1de5f616908>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9, grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
